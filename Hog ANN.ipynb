{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeet/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/jeet/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import models,Model\n",
    "from keras.layers import Dense,GaussianNoise, Dropout,Input\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "%matplotlib inline\n",
    "from skimage.feature import hog\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeet/anaconda3/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "dataSet = []\n",
    "person = []\n",
    "horiSet = []\n",
    "\n",
    "count = 0\n",
    "folder = \"/home/jeet/ML face images train\"\n",
    "for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "#         print(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img, (200,200))\n",
    "        fd, img = hog(img,visualise=True)\n",
    "        img = np.ravel(img)\n",
    "        if img is not None:\n",
    "            numbers = re.findall('\\d+',filename)\n",
    "            numbers = list(map(int,numbers))\n",
    "            person.append(numbers[0])\n",
    "            horiSet.append(img.T)\n",
    "            dataSet.append(img)\n",
    "            count = count + 1\n",
    "           \n",
    "        \n",
    "dataSet_test = []\n",
    "person_test = []\n",
    "horiSet_test = []\n",
    "\n",
    "folder = \"/home/jeet/ML face images test\"\n",
    "for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img, (200, 200))\n",
    "        fd, img = hog(img, visualise=True)\n",
    "        img = np.ravel(img)\n",
    "        if img is not None:\n",
    "            numbers = re.findall('\\d+',filename)\n",
    "            numbers = list(map(int,numbers))\n",
    "            person_test.append(numbers[0])\n",
    "            horiSet_test.append(img.T)\n",
    "            dataSet_test.append(img)\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      29\n",
      "1      32\n",
      "2       4\n",
      "3      14\n",
      "4      34\n",
      "5      35\n",
      "6      25\n",
      "7      29\n",
      "8       6\n",
      "9      18\n",
      "10     25\n",
      "11     19\n",
      "12     21\n",
      "13     24\n",
      "14     28\n",
      "15     33\n",
      "16     10\n",
      "17      2\n",
      "18      7\n",
      "19      9\n",
      "20     23\n",
      "21     31\n",
      "22     15\n",
      "23     12\n",
      "24      6\n",
      "25     21\n",
      "26     20\n",
      "27      8\n",
      "28     26\n",
      "29     34\n",
      "       ..\n",
      "110    35\n",
      "111    31\n",
      "112    15\n",
      "113    23\n",
      "114    17\n",
      "115     9\n",
      "116    33\n",
      "117    19\n",
      "118    26\n",
      "119    33\n",
      "120    23\n",
      "121    18\n",
      "122    27\n",
      "123    14\n",
      "124    10\n",
      "125     0\n",
      "126    20\n",
      "127    31\n",
      "128     6\n",
      "129    17\n",
      "130    34\n",
      "131     8\n",
      "132    35\n",
      "133    26\n",
      "134    18\n",
      "135     6\n",
      "136    30\n",
      "137    14\n",
      "138     9\n",
      "139    13\n",
      "Name: id, Length: 140, dtype: int64\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(140, 36)\n"
     ]
    }
   ],
   "source": [
    "#Getting data in desired format and mapping the lables\n",
    "dataSet = np.array(dataSet)\n",
    "train = pd.DataFrame(dataSet)\n",
    "\n",
    "person = np.array(person)\n",
    "train['id'] = person.transpose()\n",
    "\n",
    "unique_person = train['id']\n",
    "unique_person = np.array(unique_person)\n",
    "unique_person = np.unique(unique_person)\n",
    "key = range(len(unique_person))\n",
    "\n",
    "roll_dict = dict( zip(unique_person, key))\n",
    "\n",
    "mapped_roll = np.vectorize(roll_dict.get)(person)\n",
    "train['id'] = mapped_roll.transpose()\n",
    "\n",
    "y = train['id'].values.astype('int64')\n",
    "images = train.drop(['id'], axis=1, inplace=False)\n",
    "x = (images.values).astype('uint8')\n",
    "\n",
    "X_train = x\n",
    "Y_train = y\n",
    "\n",
    "dataSet_test = np.array(dataSet_test)\n",
    "test = pd.DataFrame(dataSet_test)\n",
    "\n",
    "person_test = np.array(person_test)\n",
    "test['id'] = person_test.transpose()\n",
    "\n",
    "mapped_roll_test = np.vectorize(roll_dict.get)(person_test)\n",
    "test['id'] = mapped_roll_test.transpose()\n",
    "print(test['id'])\n",
    "\n",
    "temp = np_utils.to_categorical(test['id'])\n",
    "print(temp[2])\n",
    "print(temp.shape)\n",
    "\n",
    "\n",
    "y_test = test['id'].values.astype('int64')\n",
    "images = test.drop(['id'], axis=1, inplace=False)\n",
    "x_test = (images.values).astype('uint8')\n",
    "\n",
    "X_test = x_test\n",
    "Y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 334 samples, validate on 84 samples\n",
      "Epoch 1/150\n",
      " - 2s - loss: 11.0957 - acc: 0.0240 - val_loss: 12.5449 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      " - 1s - loss: 10.3771 - acc: 0.0599 - val_loss: 6.2734 - val_acc: 0.0714\n",
      "Epoch 3/150\n",
      " - 1s - loss: 4.7831 - acc: 0.0808 - val_loss: 3.5565 - val_acc: 0.0476\n",
      "Epoch 4/150\n",
      " - 1s - loss: 3.4939 - acc: 0.0629 - val_loss: 3.4720 - val_acc: 0.0238\n",
      "Epoch 5/150\n",
      " - 1s - loss: 3.3521 - acc: 0.0838 - val_loss: 3.3946 - val_acc: 0.0476\n",
      "Epoch 6/150\n",
      " - 1s - loss: 3.2511 - acc: 0.0778 - val_loss: 3.3135 - val_acc: 0.0714\n",
      "Epoch 7/150\n",
      " - 1s - loss: 3.1844 - acc: 0.1018 - val_loss: 3.3146 - val_acc: 0.0833\n",
      "Epoch 8/150\n",
      " - 1s - loss: 3.1427 - acc: 0.0928 - val_loss: 3.3432 - val_acc: 0.0595\n",
      "Epoch 9/150\n",
      " - 1s - loss: 3.0791 - acc: 0.1078 - val_loss: 3.2651 - val_acc: 0.0833\n",
      "Epoch 10/150\n",
      " - 1s - loss: 2.9562 - acc: 0.1557 - val_loss: 3.1945 - val_acc: 0.1071\n",
      "Epoch 11/150\n",
      " - 1s - loss: 2.8975 - acc: 0.1677 - val_loss: 3.3805 - val_acc: 0.1190\n",
      "Epoch 12/150\n",
      " - 1s - loss: 2.9288 - acc: 0.1647 - val_loss: 3.2032 - val_acc: 0.1071\n",
      "Epoch 13/150\n",
      " - 1s - loss: 2.9142 - acc: 0.1766 - val_loss: 3.2322 - val_acc: 0.0833\n",
      "Epoch 14/150\n",
      " - 1s - loss: 2.8330 - acc: 0.2126 - val_loss: 3.1554 - val_acc: 0.1310\n",
      "Epoch 15/150\n",
      " - 1s - loss: 2.7867 - acc: 0.2036 - val_loss: 3.1830 - val_acc: 0.1190\n",
      "Epoch 16/150\n",
      " - 1s - loss: 2.6852 - acc: 0.2066 - val_loss: 3.1329 - val_acc: 0.1548\n",
      "Epoch 17/150\n",
      " - 1s - loss: 2.5538 - acc: 0.2635 - val_loss: 3.0750 - val_acc: 0.1190\n",
      "Epoch 18/150\n",
      " - 1s - loss: 2.4451 - acc: 0.2934 - val_loss: 3.1269 - val_acc: 0.1786\n",
      "Epoch 19/150\n",
      " - 1s - loss: 2.4669 - acc: 0.2784 - val_loss: 3.0933 - val_acc: 0.1429\n",
      "Epoch 20/150\n",
      " - 1s - loss: 2.3563 - acc: 0.3114 - val_loss: 3.0223 - val_acc: 0.1667\n",
      "Epoch 21/150\n",
      " - 1s - loss: 2.2823 - acc: 0.3234 - val_loss: 2.9885 - val_acc: 0.1905\n",
      "Epoch 22/150\n",
      " - 1s - loss: 2.3368 - acc: 0.3144 - val_loss: 3.0170 - val_acc: 0.1310\n",
      "Epoch 23/150\n",
      " - 1s - loss: 2.2951 - acc: 0.3323 - val_loss: 3.1353 - val_acc: 0.1667\n",
      "Epoch 24/150\n",
      " - 1s - loss: 2.2400 - acc: 0.3234 - val_loss: 3.1292 - val_acc: 0.2381\n",
      "Epoch 25/150\n",
      " - 1s - loss: 2.1001 - acc: 0.4042 - val_loss: 3.2006 - val_acc: 0.2143\n",
      "Epoch 26/150\n",
      " - 1s - loss: 2.2687 - acc: 0.3593 - val_loss: 2.9979 - val_acc: 0.2024\n",
      "Epoch 27/150\n",
      " - 1s - loss: 2.2535 - acc: 0.3653 - val_loss: 2.8689 - val_acc: 0.2262\n",
      "Epoch 28/150\n",
      " - 1s - loss: 2.1370 - acc: 0.3772 - val_loss: 3.0318 - val_acc: 0.2500\n",
      "Epoch 29/150\n",
      " - 1s - loss: 2.0933 - acc: 0.4132 - val_loss: 2.9603 - val_acc: 0.2500\n",
      "Epoch 30/150\n",
      " - 1s - loss: 2.1287 - acc: 0.3683 - val_loss: 2.8938 - val_acc: 0.2262\n",
      "Epoch 31/150\n",
      " - 1s - loss: 2.2351 - acc: 0.3593 - val_loss: 3.1577 - val_acc: 0.2143\n",
      "Epoch 32/150\n",
      " - 1s - loss: 2.0590 - acc: 0.3832 - val_loss: 3.0769 - val_acc: 0.2500\n",
      "Epoch 33/150\n",
      " - 1s - loss: 2.0114 - acc: 0.3952 - val_loss: 2.8983 - val_acc: 0.2381\n",
      "Epoch 34/150\n",
      " - 1s - loss: 1.9050 - acc: 0.4401 - val_loss: 3.6201 - val_acc: 0.2619\n",
      "Epoch 35/150\n",
      " - 1s - loss: 2.0239 - acc: 0.4072 - val_loss: 3.2781 - val_acc: 0.2738\n",
      "Epoch 36/150\n",
      " - 1s - loss: 1.9548 - acc: 0.4192 - val_loss: 3.0616 - val_acc: 0.2857\n",
      "Epoch 37/150\n",
      " - 1s - loss: 2.0619 - acc: 0.3832 - val_loss: 2.7120 - val_acc: 0.3095\n",
      "Epoch 38/150\n",
      " - 1s - loss: 2.0097 - acc: 0.4371 - val_loss: 2.8293 - val_acc: 0.2619\n",
      "Epoch 39/150\n",
      " - 1s - loss: 1.9137 - acc: 0.4401 - val_loss: 2.6175 - val_acc: 0.3452\n",
      "Epoch 40/150\n",
      " - 1s - loss: 1.7887 - acc: 0.4641 - val_loss: 2.8378 - val_acc: 0.3214\n",
      "Epoch 41/150\n",
      " - 1s - loss: 1.7921 - acc: 0.4671 - val_loss: 3.0399 - val_acc: 0.3095\n",
      "Epoch 42/150\n",
      " - 1s - loss: 1.8225 - acc: 0.4760 - val_loss: 2.7059 - val_acc: 0.3571\n",
      "Epoch 43/150\n",
      " - 1s - loss: 1.6355 - acc: 0.5210 - val_loss: 2.8372 - val_acc: 0.2738\n",
      "Epoch 44/150\n",
      " - 1s - loss: 1.6853 - acc: 0.5000 - val_loss: 2.6765 - val_acc: 0.3452\n",
      "Epoch 45/150\n",
      " - 1s - loss: 1.6015 - acc: 0.5269 - val_loss: 2.5931 - val_acc: 0.3333\n",
      "Epoch 46/150\n",
      " - 1s - loss: 1.5123 - acc: 0.5599 - val_loss: 2.7368 - val_acc: 0.3333\n",
      "Epoch 47/150\n",
      " - 1s - loss: 1.5740 - acc: 0.5479 - val_loss: 2.6438 - val_acc: 0.3571\n",
      "Epoch 48/150\n",
      " - 1s - loss: 1.5121 - acc: 0.5599 - val_loss: 2.4500 - val_acc: 0.3810\n",
      "Epoch 49/150\n",
      " - 1s - loss: 1.4740 - acc: 0.5719 - val_loss: 2.5653 - val_acc: 0.3333\n",
      "Epoch 50/150\n",
      " - 1s - loss: 1.6093 - acc: 0.5240 - val_loss: 3.2124 - val_acc: 0.2619\n",
      "Epoch 51/150\n",
      " - 1s - loss: 1.7257 - acc: 0.5060 - val_loss: 2.8305 - val_acc: 0.3095\n",
      "Epoch 52/150\n",
      " - 1s - loss: 1.5443 - acc: 0.5030 - val_loss: 3.4365 - val_acc: 0.2857\n",
      "Epoch 53/150\n",
      " - 1s - loss: 1.6749 - acc: 0.5389 - val_loss: 2.5370 - val_acc: 0.3095\n",
      "Epoch 54/150\n",
      " - 1s - loss: 1.6256 - acc: 0.4701 - val_loss: 2.7753 - val_acc: 0.2500\n",
      "Epoch 55/150\n",
      " - 1s - loss: 1.8125 - acc: 0.4880 - val_loss: 2.7961 - val_acc: 0.3333\n",
      "Epoch 56/150\n",
      " - 1s - loss: 1.5856 - acc: 0.5329 - val_loss: 2.7802 - val_acc: 0.2262\n",
      "Epoch 57/150\n",
      " - 1s - loss: 1.6705 - acc: 0.5060 - val_loss: 2.5647 - val_acc: 0.2262\n",
      "Epoch 58/150\n",
      " - 1s - loss: 1.4891 - acc: 0.5479 - val_loss: 2.5579 - val_acc: 0.3333\n",
      "Epoch 59/150\n",
      " - 1s - loss: 1.4425 - acc: 0.5749 - val_loss: 2.7502 - val_acc: 0.3214\n",
      "Epoch 60/150\n",
      " - 1s - loss: 1.5525 - acc: 0.5419 - val_loss: 2.2421 - val_acc: 0.3095\n",
      "Epoch 61/150\n",
      " - 1s - loss: 1.4836 - acc: 0.5539 - val_loss: 2.3619 - val_acc: 0.3214\n",
      "Epoch 62/150\n",
      " - 1s - loss: 1.4638 - acc: 0.5479 - val_loss: 2.8991 - val_acc: 0.2857\n",
      "Epoch 63/150\n",
      " - 1s - loss: 1.3607 - acc: 0.5868 - val_loss: 2.9479 - val_acc: 0.2857\n",
      "Epoch 64/150\n",
      " - 1s - loss: 1.4615 - acc: 0.5868 - val_loss: 2.2929 - val_acc: 0.3929\n",
      "Epoch 65/150\n",
      " - 1s - loss: 1.3149 - acc: 0.5988 - val_loss: 2.9944 - val_acc: 0.3095\n",
      "Epoch 66/150\n",
      " - 1s - loss: 1.3246 - acc: 0.6287 - val_loss: 2.6726 - val_acc: 0.4524\n",
      "Epoch 67/150\n",
      " - 1s - loss: 1.3678 - acc: 0.5928 - val_loss: 2.6784 - val_acc: 0.3571\n",
      "Epoch 68/150\n",
      " - 1s - loss: 1.3888 - acc: 0.5569 - val_loss: 2.4201 - val_acc: 0.3571\n",
      "Epoch 69/150\n",
      " - 1s - loss: 1.3747 - acc: 0.5898 - val_loss: 2.6941 - val_acc: 0.3810\n",
      "Epoch 70/150\n",
      " - 1s - loss: 1.1697 - acc: 0.6287 - val_loss: 2.6197 - val_acc: 0.3690\n",
      "Epoch 71/150\n",
      " - 1s - loss: 1.3419 - acc: 0.6138 - val_loss: 2.6341 - val_acc: 0.3690\n",
      "Epoch 72/150\n",
      " - 1s - loss: 1.2881 - acc: 0.6377 - val_loss: 2.8413 - val_acc: 0.2857\n",
      "Epoch 73/150\n",
      " - 1s - loss: 1.2222 - acc: 0.6257 - val_loss: 2.5070 - val_acc: 0.4286\n",
      "Epoch 74/150\n",
      " - 1s - loss: 1.1775 - acc: 0.6617 - val_loss: 2.6083 - val_acc: 0.4405\n",
      "Epoch 75/150\n",
      " - 1s - loss: 1.3047 - acc: 0.6347 - val_loss: 2.4724 - val_acc: 0.4048\n",
      "Epoch 76/150\n",
      " - 1s - loss: 1.2041 - acc: 0.6437 - val_loss: 2.2700 - val_acc: 0.4286\n",
      "Epoch 77/150\n",
      " - 1s - loss: 1.1067 - acc: 0.6557 - val_loss: 2.9551 - val_acc: 0.3810\n",
      "Epoch 78/150\n",
      " - 1s - loss: 1.1777 - acc: 0.6617 - val_loss: 2.7373 - val_acc: 0.4286\n",
      "Epoch 79/150\n",
      " - 1s - loss: 1.2075 - acc: 0.6826 - val_loss: 3.3765 - val_acc: 0.3571\n",
      "Epoch 80/150\n",
      " - 1s - loss: 1.1871 - acc: 0.6377 - val_loss: 2.4979 - val_acc: 0.4048\n",
      "Epoch 81/150\n",
      " - 1s - loss: 1.1215 - acc: 0.6766 - val_loss: 2.5463 - val_acc: 0.3810\n",
      "Epoch 82/150\n",
      " - 1s - loss: 1.1207 - acc: 0.6976 - val_loss: 2.5083 - val_acc: 0.4048\n",
      "Epoch 83/150\n",
      " - 1s - loss: 1.1105 - acc: 0.6647 - val_loss: 2.6192 - val_acc: 0.4048\n",
      "Epoch 84/150\n",
      " - 1s - loss: 0.9950 - acc: 0.6856 - val_loss: 2.4099 - val_acc: 0.4048\n",
      "Epoch 85/150\n",
      " - 1s - loss: 1.0785 - acc: 0.6796 - val_loss: 2.7185 - val_acc: 0.4405\n",
      "Epoch 86/150\n",
      " - 1s - loss: 1.0236 - acc: 0.6856 - val_loss: 2.6551 - val_acc: 0.4286\n",
      "Epoch 87/150\n",
      " - 1s - loss: 1.0007 - acc: 0.6856 - val_loss: 2.6331 - val_acc: 0.4167\n",
      "Epoch 88/150\n",
      " - 1s - loss: 1.0044 - acc: 0.7305 - val_loss: 2.5593 - val_acc: 0.4286\n",
      "Epoch 89/150\n",
      " - 1s - loss: 0.8635 - acc: 0.7305 - val_loss: 2.4838 - val_acc: 0.3929\n",
      "Epoch 90/150\n",
      " - 1s - loss: 0.9549 - acc: 0.7066 - val_loss: 2.4191 - val_acc: 0.4048\n",
      "Epoch 91/150\n",
      " - 1s - loss: 0.8379 - acc: 0.7455 - val_loss: 2.6428 - val_acc: 0.4167\n",
      "Epoch 92/150\n",
      " - 1s - loss: 0.9122 - acc: 0.7335 - val_loss: 2.3794 - val_acc: 0.4286\n",
      "Epoch 93/150\n",
      " - 1s - loss: 1.0082 - acc: 0.7275 - val_loss: 2.3320 - val_acc: 0.4048\n",
      "Epoch 94/150\n",
      " - 1s - loss: 0.9330 - acc: 0.7575 - val_loss: 2.4238 - val_acc: 0.4643\n",
      "Epoch 95/150\n",
      " - 1s - loss: 0.9255 - acc: 0.7335 - val_loss: 2.1955 - val_acc: 0.4524\n",
      "Epoch 96/150\n",
      " - 1s - loss: 0.7646 - acc: 0.7635 - val_loss: 2.7490 - val_acc: 0.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150\n",
      " - 1s - loss: 0.8719 - acc: 0.7275 - val_loss: 2.3995 - val_acc: 0.4762\n",
      "Epoch 98/150\n",
      " - 1s - loss: 0.8157 - acc: 0.7635 - val_loss: 2.1582 - val_acc: 0.4881\n",
      "Epoch 99/150\n",
      " - 1s - loss: 0.8414 - acc: 0.7515 - val_loss: 2.3208 - val_acc: 0.5119\n",
      "Epoch 100/150\n",
      " - 1s - loss: 0.7009 - acc: 0.7725 - val_loss: 2.3398 - val_acc: 0.4762\n",
      "Epoch 101/150\n",
      " - 1s - loss: 0.7736 - acc: 0.7605 - val_loss: 2.4930 - val_acc: 0.4524\n",
      "Epoch 102/150\n",
      " - 1s - loss: 0.9109 - acc: 0.7575 - val_loss: 2.3775 - val_acc: 0.4524\n",
      "Epoch 103/150\n",
      " - 1s - loss: 0.8351 - acc: 0.7784 - val_loss: 2.3026 - val_acc: 0.4048\n",
      "Epoch 104/150\n",
      " - 1s - loss: 0.6651 - acc: 0.8084 - val_loss: 2.3512 - val_acc: 0.4643\n",
      "Epoch 105/150\n",
      " - 1s - loss: 0.7232 - acc: 0.7934 - val_loss: 2.4222 - val_acc: 0.4762\n",
      "Epoch 106/150\n",
      " - 1s - loss: 0.6952 - acc: 0.8054 - val_loss: 2.3703 - val_acc: 0.4167\n",
      "Epoch 107/150\n",
      " - 1s - loss: 0.6901 - acc: 0.7844 - val_loss: 2.1205 - val_acc: 0.5000\n",
      "Epoch 108/150\n",
      " - 1s - loss: 0.7832 - acc: 0.7754 - val_loss: 2.4647 - val_acc: 0.4405\n",
      "Epoch 109/150\n",
      " - 1s - loss: 0.7273 - acc: 0.7784 - val_loss: 2.7391 - val_acc: 0.4762\n",
      "Epoch 110/150\n",
      " - 1s - loss: 0.7729 - acc: 0.7784 - val_loss: 2.6106 - val_acc: 0.4405\n",
      "Epoch 111/150\n",
      " - 1s - loss: 0.6904 - acc: 0.7934 - val_loss: 2.0665 - val_acc: 0.4881\n",
      "Epoch 112/150\n",
      " - 1s - loss: 0.7380 - acc: 0.7784 - val_loss: 2.0216 - val_acc: 0.5357\n",
      "Epoch 113/150\n",
      " - 1s - loss: 0.6902 - acc: 0.7904 - val_loss: 3.3824 - val_acc: 0.3452\n",
      "Epoch 114/150\n",
      " - 1s - loss: 0.6814 - acc: 0.7994 - val_loss: 2.7063 - val_acc: 0.4881\n",
      "Epoch 115/150\n",
      " - 1s - loss: 0.6584 - acc: 0.8054 - val_loss: 2.2738 - val_acc: 0.4405\n",
      "Epoch 116/150\n",
      " - 1s - loss: 0.5315 - acc: 0.8323 - val_loss: 2.3724 - val_acc: 0.4524\n",
      "Epoch 117/150\n",
      " - 1s - loss: 0.7153 - acc: 0.8084 - val_loss: 2.2070 - val_acc: 0.4881\n",
      "Epoch 118/150\n",
      " - 1s - loss: 0.5181 - acc: 0.8563 - val_loss: 2.0835 - val_acc: 0.5119\n",
      "Epoch 119/150\n",
      " - 1s - loss: 0.6035 - acc: 0.8323 - val_loss: 1.9266 - val_acc: 0.5476\n",
      "Epoch 120/150\n",
      " - 1s - loss: 0.5629 - acc: 0.8473 - val_loss: 1.8659 - val_acc: 0.5357\n",
      "Epoch 121/150\n",
      " - 1s - loss: 0.6205 - acc: 0.8323 - val_loss: 2.1355 - val_acc: 0.5119\n",
      "Epoch 122/150\n",
      " - 1s - loss: 0.4899 - acc: 0.8593 - val_loss: 2.4245 - val_acc: 0.4643\n",
      "Epoch 123/150\n",
      " - 1s - loss: 0.6182 - acc: 0.8293 - val_loss: 2.1064 - val_acc: 0.5595\n",
      "Epoch 124/150\n",
      " - 1s - loss: 0.4828 - acc: 0.8593 - val_loss: 2.2344 - val_acc: 0.5952\n",
      "Epoch 125/150\n",
      " - 1s - loss: 0.6105 - acc: 0.8174 - val_loss: 2.5422 - val_acc: 0.5119\n",
      "Epoch 126/150\n",
      " - 1s - loss: 0.5710 - acc: 0.8234 - val_loss: 2.2898 - val_acc: 0.5000\n",
      "Epoch 127/150\n",
      " - 1s - loss: 0.5400 - acc: 0.8443 - val_loss: 2.1061 - val_acc: 0.5595\n",
      "Epoch 128/150\n",
      " - 1s - loss: 0.5462 - acc: 0.8413 - val_loss: 2.1397 - val_acc: 0.5238\n",
      "Epoch 129/150\n",
      " - 1s - loss: 0.5723 - acc: 0.8234 - val_loss: 2.2990 - val_acc: 0.5000\n",
      "Epoch 130/150\n",
      " - 1s - loss: 0.5394 - acc: 0.8413 - val_loss: 2.2169 - val_acc: 0.5595\n",
      "Epoch 131/150\n",
      " - 1s - loss: 0.5626 - acc: 0.8503 - val_loss: 2.1118 - val_acc: 0.5595\n",
      "Epoch 132/150\n",
      " - 1s - loss: 0.3854 - acc: 0.8952 - val_loss: 2.5312 - val_acc: 0.5119\n",
      "Epoch 133/150\n",
      " - 1s - loss: 0.5505 - acc: 0.8473 - val_loss: 2.4581 - val_acc: 0.5238\n",
      "Epoch 134/150\n",
      " - 1s - loss: 0.4890 - acc: 0.8503 - val_loss: 2.4051 - val_acc: 0.5595\n",
      "Epoch 135/150\n",
      " - 1s - loss: 0.4813 - acc: 0.8683 - val_loss: 2.6477 - val_acc: 0.5238\n",
      "Epoch 136/150\n",
      " - 1s - loss: 0.4715 - acc: 0.8772 - val_loss: 2.3647 - val_acc: 0.5238\n",
      "Epoch 137/150\n",
      " - 1s - loss: 0.5497 - acc: 0.8503 - val_loss: 2.4100 - val_acc: 0.5476\n",
      "Epoch 138/150\n",
      " - 1s - loss: 0.4950 - acc: 0.8623 - val_loss: 2.3910 - val_acc: 0.5119\n",
      "Epoch 139/150\n",
      " - 1s - loss: 0.5339 - acc: 0.8533 - val_loss: 2.6219 - val_acc: 0.5238\n",
      "Epoch 140/150\n",
      " - 1s - loss: 0.5219 - acc: 0.8503 - val_loss: 2.6028 - val_acc: 0.4643\n",
      "Epoch 141/150\n",
      " - 1s - loss: 0.5082 - acc: 0.8563 - val_loss: 3.2587 - val_acc: 0.4762\n",
      "Epoch 142/150\n",
      " - 1s - loss: 0.5096 - acc: 0.8713 - val_loss: 2.5567 - val_acc: 0.5119\n",
      "Epoch 143/150\n",
      " - 1s - loss: 0.5396 - acc: 0.8293 - val_loss: 2.1975 - val_acc: 0.5476\n",
      "Epoch 144/150\n",
      " - 1s - loss: 0.4429 - acc: 0.8593 - val_loss: 2.2956 - val_acc: 0.5357\n",
      "Epoch 145/150\n",
      " - 1s - loss: 0.4752 - acc: 0.8503 - val_loss: 2.0526 - val_acc: 0.5833\n",
      "Epoch 146/150\n",
      " - 1s - loss: 0.4829 - acc: 0.8593 - val_loss: 2.1159 - val_acc: 0.5476\n",
      "Epoch 147/150\n",
      " - 1s - loss: 0.3825 - acc: 0.8922 - val_loss: 2.1258 - val_acc: 0.5952\n",
      "Epoch 148/150\n",
      " - 1s - loss: 0.4685 - acc: 0.8653 - val_loss: 2.2168 - val_acc: 0.5714\n",
      "Epoch 149/150\n",
      " - 1s - loss: 0.4192 - acc: 0.8772 - val_loss: 2.2205 - val_acc: 0.5833\n",
      "Epoch 150/150\n",
      " - 1s - loss: 0.4025 - acc: 0.8743 - val_loss: 3.3778 - val_acc: 0.5476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3df922b208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining and training of the neural neural network\n",
    "model = models.Sequential()\n",
    "layers = 2\n",
    "units = 256\n",
    "\n",
    "#Input layer\n",
    "model.add(Dense(units, input_dim=40000, activation='relu'))\n",
    "\n",
    "#Hidden Layer\n",
    "for i in range(layers):\n",
    "    model.add(Dense(72, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "#Output layer\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "#Building model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Training model\n",
    "model.fit(X_train,Y_train,batch_size=70,validation_split=0.2,epochs=150,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "def write_predictions(predictions, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"id\": predictions}).to_csv(fname, index=False, header=True)\n",
    "\n",
    "write_predictions(predictions, \"out.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5857142857142856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24, 34,  4,  5, 34, 35, 27, 10, 28, 31, 25, 19, 21, 15, 28,  0,  8,\n",
       "        2, 31, 21, 23,  0, 15, 12,  6, 21, 20,  8, 21, 31,  4,  4, 22,  1,\n",
       "       30, 13, 21, 22, 31, 16, 17, 21, 15, 13, 22, 16,  2, 31,  0,  8,  8,\n",
       "       17, 19, 16, 27,  8, 24, 18,  9, 13, 12, 13,  8, 30, 29, 27,  8, 24,\n",
       "       11, 21, 20, 16, 19, 13, 31, 16, 35, 29, 16,  1, 16, 28,  3, 28, 21,\n",
       "       34, 22,  0, 29, 22,  8,  7, 24, 26, 10, 32, 35, 12, 14,  0, 30,  0,\n",
       "       27,  8, 10, 28,  0, 13,  4, 31, 35, 16, 15,  0, 17, 29, 21, 19, 26,\n",
       "       33,  6, 31, 27, 14, 10,  0, 31, 13, 28, 17, 34,  8, 35, 26, 18,  6,\n",
       "       30, 14, 30, 13])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('out.csv')\n",
    "result = result['id']\n",
    "result = np.array(result)\n",
    "error = np.array(Y_test - result)\n",
    "error = error[error != 0]\n",
    "error = error.size/Y_test.size\n",
    "\n",
    "print('Accuracy : ',1-error)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score, micro-averaged over all classes: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(36):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(temp[:, i],\n",
    "                                                        score[:, i])\n",
    "    average_precision[i] = average_precision_score(temp[:, i], score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(temp.ravel(),\n",
    "    score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(temp, score,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], color='b', alpha=0.9,\n",
    "         where='post')\n",
    "#plt.fill_between(recall[\"micro\"], precision[\"micro\"], step='post', alpha=0.2,\n",
    "#                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(average_precision[\"micro\"]))\n",
    "plt.show()\n",
    "fig.savefig('HOG-ANN.png',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
